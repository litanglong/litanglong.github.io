'use strict';

var browserFakeUserAgent, requestAnimationFrame, lastTime, cancelAnimationFrame, AudioContext, URL, isEdge, isOpera, isFirefox, isChrome, isSafari, MediaStream, Storage, Whammy, DiskStorage;

function RecordRTC(mediaStream, config) {
    var mediaRecorder, self, returnObject, prop;
    function initRecorder(initCallback) {
        initCallback && (config.initCallback = function() {
            initCallback(), initCallback = config.initCallback = null;
        });
        var Recorder = new GetRecorderType(mediaStream, config);
        (mediaRecorder = new Recorder(mediaStream, config)).record(), setState('recording'), 
        config.disableLogs;
    }
    function stopRecording(callback) {
        function _callback(__blob) {
            var blob, url;
            if (!mediaRecorder) return void ('function' == typeof callback.call ? callback.call(self, '') : callback(''));
            Object.keys(mediaRecorder).forEach(function(key) {
                'function' != typeof mediaRecorder[key] && (self[key] = mediaRecorder[key]);
            });
            if (!(blob = mediaRecorder.blob)) {
                if (!__blob) throw 'Recording failed.';
                mediaRecorder.blob = blob = __blob;
            }
            if (blob && config.disableLogs, callback) {
                try {
                    url = URL.createObjectURL(blob);
                } catch (e) {}
                'function' == typeof callback.call ? callback.call(self, url) : callback(url);
            }
            config.autoWriteToDisk && getDataURL(function(dataURL) {
                var parameter = {};
                parameter[config.type + 'Blob'] = dataURL, DiskStorage.Store(parameter);
            });
        }
        return callback = callback || function() {}, mediaRecorder ? 'paused' === self.state ? (self.resumeRecording(), 
        void setTimeout(function() {
            stopRecording(callback);
        }, 1)) : ('recording' !== self.state && config.disableLogs, config.disableLogs, 
        'gif' !== config.type ? mediaRecorder.stop(_callback) : (mediaRecorder.stop(), 
        _callback()), void setState('stopped')) : void warningLog();
    }
    function readFile(_blob) {
        postMessage(new FileReaderSync().readAsDataURL(_blob));
    }
    function getDataURL(callback, _mediaRecorder) {
        var blob, reader;
        if (!callback) throw 'Pass a callback function over getDataURL.';
        if (!(blob = (_mediaRecorder || mediaRecorder || {}).blob)) return config.disableLogs, 
        void setTimeout(function() {
            getDataURL(callback, _mediaRecorder);
        }, 1e3);
        'undefined' == typeof Worker || navigator.mozGetUserMedia ? ((reader = new FileReader()).readAsDataURL(blob), 
        reader.onload = function(event) {
            callback(event.target.result);
        }) : ((reader = function(_function) {
            try {
                var blob = URL.createObjectURL(new Blob([ _function.toString(), 'this.onmessage =  function (eee) {' + _function.name + '(eee.data);}' ], {
                    'type': 'application/javascript'
                })), worker = new Worker(blob);
                return URL.revokeObjectURL(blob), worker;
            } catch (e) {}
        }(readFile)).onmessage = function(event) {
            callback(event.data);
        }, reader.postMessage(blob));
    }
    function handleRecordingDuration(counter) {
        if (counter = counter || 0, 'paused' === self.state) return setTimeout(function() {
            handleRecordingDuration(counter);
        }, 1e3);
        if ('stopped' !== self.state) {
            if (counter >= self.recordingDuration) return stopRecording(self.onRecordingStopped);
            counter += 1e3, setTimeout(function() {
                handleRecordingDuration(counter);
            }, 1e3);
        }
    }
    function setState(state) {
        self && (self.state = state, 'function' == typeof self.onStateChanged.call ? self.onStateChanged.call(self, state) : self.onStateChanged(state));
    }
    function warningLog() {
        config.disableLogs;
    }
    if (!mediaStream) throw 'First parameter is required.';
    config = new RecordRTCConfiguration(mediaStream, config = config || {
        'type': 'video'
    });
    self = this, config.type, returnObject = {
        'startRecording': function(config2) {
            return config.disableLogs, (config = config2 ? new RecordRTCConfiguration(mediaStream, config2) : config).disableLogs, 
            mediaRecorder ? (mediaRecorder.clearRecordedData(), mediaRecorder.record(), 
            setState('recording'), self.recordingDuration && handleRecordingDuration()) : initRecorder(function() {
                self.recordingDuration && handleRecordingDuration();
            }), self;
        },
        'stopRecording': stopRecording,
        'pauseRecording': function() {
            return mediaRecorder ? ('recording' !== self.state || (setState('paused'), 
            mediaRecorder.pause()), void config.disableLogs) : void warningLog();
        },
        'resumeRecording': function() {
            return mediaRecorder ? ('paused' !== self.state || (setState('recording'), 
            mediaRecorder.resume()), void config.disableLogs) : void warningLog();
        },
        'initRecorder': initRecorder,
        'setRecordingDuration': function(recordingDuration, callback) {
            if (void 0 === recordingDuration) throw 'recordingDuration is required.';
            if ('number' != typeof recordingDuration) throw 'recordingDuration must be a number.';
            return self.recordingDuration = recordingDuration, self.onRecordingStopped = callback || function() {}, 
            {
                'onRecordingStopped': function(callback) {
                    self.onRecordingStopped = callback;
                }
            };
        },
        'clearRecordedData': function() {
            return mediaRecorder ? (mediaRecorder.clearRecordedData(), void config.disableLogs) : void warningLog();
        },
        'getBlob': function() {
            return mediaRecorder ? mediaRecorder.blob : void warningLog();
        },
        'getDataURL': getDataURL,
        'toURL': function() {
            return mediaRecorder ? URL.createObjectURL(mediaRecorder.blob) : void warningLog();
        },
        'getInternalRecorder': function() {
            return mediaRecorder;
        },
        'save': function(fileName) {
            return mediaRecorder ? void invokeSaveAsDialog(mediaRecorder.blob, fileName) : void warningLog();
        },
        'getFromDisk': function(callback) {
            return mediaRecorder ? void RecordRTC.getFromDisk(config.type, callback) : void warningLog();
        },
        'setAdvertisementArray': function(arrayOfWebPImages) {
            config.advertisement = [];
            for (var length = arrayOfWebPImages.length, i = 0; i < length; i++) config.advertisement.push({
                'duration': i,
                'image': arrayOfWebPImages[i]
            });
        },
        'blob': null,
        'bufferSize': 0,
        'sampleRate': 0,
        'buffer': null,
        'reset': function() {
            'recording' === self.state && config.disableLogs, mediaRecorder && 'function' == typeof mediaRecorder.clearRecordedData && mediaRecorder.clearRecordedData(), 
            mediaRecorder = null, setState('inactive'), self.blob = null;
        },
        'onStateChanged': function(state) {
            config.disableLogs;
        },
        'state': 'inactive',
        'getState': function() {
            return self.state;
        },
        'destroy': function() {
            var disableLogsCache = config.disableLogs;
            config = {
                'disableLogs': !0
            }, self.reset(), setState('destroyed'), returnObject = self = null, 
            Storage.AudioContextConstructor && (Storage.AudioContextConstructor.close(), 
            Storage.AudioContextConstructor = null), config.disableLogs = disableLogsCache, 
            config.disableLogs;
        },
        'version': '5.5.9'
    };
    if (!this) return self = returnObject;
    for (prop in returnObject) this[prop] = returnObject[prop];
    return self = this, returnObject;
}

function RecordRTCConfiguration(mediaStream, config) {
    return config.recorderType || config.type || (config.audio && config.video ? config.type = 'video' : config.audio && !config.video && (config.type = 'audio')), 
    config.recorderType && !config.type && (config.recorderType === WhammyRecorder || config.recorderType === CanvasRecorder || void 0 !== WebAssemblyRecorder && config.recorderType === WebAssemblyRecorder ? config.type = 'video' : config.recorderType === GifRecorder ? config.type = 'gif' : config.recorderType === StereoAudioRecorder ? config.type = 'audio' : config.recorderType === MediaStreamRecorder && (getTracks(mediaStream, 'audio').length && getTracks(mediaStream, 'video').length || !getTracks(mediaStream, 'audio').length && getTracks(mediaStream, 'video').length ? config.type = 'video' : getTracks(mediaStream, 'audio').length && !getTracks(mediaStream, 'video').length && (config.type = 'audio'))), 
    void 0 !== MediaStreamRecorder && 'undefined' != typeof MediaRecorder && 'requestData' in MediaRecorder.prototype && (config.mimeType || (config.mimeType = 'video/webm'), 
    config.type || (config.type = config.mimeType.split('/')[0]), config.bitsPerSecond), 
    config.type || (config.mimeType && (config.type = config.mimeType.split('/')[0]), 
    config.type) || (config.type = 'audio'), config;
}

function GetRecorderType(mediaStream, config) {
    var recorder;
    return (isChrome || isEdge || isOpera) && (recorder = StereoAudioRecorder), 
    'undefined' != typeof MediaRecorder && 'requestData' in MediaRecorder.prototype && !isChrome && (recorder = MediaStreamRecorder), 
    'video' === config.type && (isChrome || isOpera) && (recorder = WhammyRecorder, 
    void 0 !== WebAssemblyRecorder) && 'undefined' != typeof ReadableStream && (recorder = WebAssemblyRecorder), 
    'gif' === config.type && (recorder = GifRecorder), 'canvas' === config.type && (recorder = CanvasRecorder), 
    isMediaRecorderCompatible() && recorder !== CanvasRecorder && recorder !== GifRecorder && 'undefined' != typeof MediaRecorder && 'requestData' in MediaRecorder.prototype && (getTracks(mediaStream, 'video').length || getTracks(mediaStream, 'audio').length) && ('audio' === config.type ? 'function' == typeof MediaRecorder.isTypeSupported && MediaRecorder.isTypeSupported('audio/webm') && (recorder = MediaStreamRecorder) : 'function' == typeof MediaRecorder.isTypeSupported && MediaRecorder.isTypeSupported('video/webm') && (recorder = MediaStreamRecorder)), 
    mediaStream instanceof Array && mediaStream.length && (recorder = MultiStreamRecorder), 
    config.recorderType && (recorder = config.recorderType), !config.disableLogs && recorder && recorder.name, 
    recorder = !recorder && isSafari ? MediaStreamRecorder : recorder;
}

function MRecordRTC(mediaStream) {
    this.addStream = function(_mediaStream) {
        _mediaStream && (mediaStream = _mediaStream);
    }, this.mediaType = {
        'audio': !0,
        'video': !0
    }, this.startRecording = function() {
        var recorderType, mediaType, mimeType, newStream, self, videoTrack;
        mediaType = this.mediaType, mimeType = this.mimeType || {
            'audio': null,
            'video': null,
            'gif': null
        };
        if ('function' != typeof mediaType.audio && isMediaRecorderCompatible() && !getTracks(mediaStream, 'audio').length && (mediaType.audio = !1), 
        'function' != typeof mediaType.video && isMediaRecorderCompatible() && !getTracks(mediaStream, 'video').length && (mediaType.video = !1), 
        'function' != typeof mediaType.gif && isMediaRecorderCompatible() && !getTracks(mediaStream, 'video').length && (mediaType.gif = !1), 
        !mediaType.audio && !mediaType.video && !mediaType.gif) throw 'MediaStream must have either audio or video tracks.';
        if (mediaType.audio && (recorderType = null, 'function' == typeof mediaType.audio && (recorderType = mediaType.audio), 
        this.audioRecorder = new RecordRTC(mediaStream, {
            'type': 'audio',
            'bufferSize': this.bufferSize,
            'sampleRate': this.sampleRate,
            'numberOfAudioChannels': this.numberOfAudioChannels || 2,
            'disableLogs': this.disableLogs,
            'recorderType': recorderType,
            'mimeType': mimeType.audio,
            'timeSlice': this.timeSlice,
            'onTimeStamp': this.onTimeStamp
        }), mediaType.video || this.audioRecorder.startRecording()), mediaType.video) {
            recorderType = null, 'function' == typeof mediaType.video && (recorderType = mediaType.video);
            newStream = mediaStream;
            if (isMediaRecorderCompatible() && mediaType.audio && 'function' == typeof mediaType.audio) {
                videoTrack = getTracks(mediaStream, 'video')[0];
                isFirefox ? ((newStream = new MediaStream()).addTrack(videoTrack), 
                recorderType && recorderType === WhammyRecorder && (recorderType = MediaStreamRecorder)) : (newStream = new MediaStream()).addTrack(videoTrack);
            }
            this.videoRecorder = new RecordRTC(newStream, {
                'type': 'video',
                'video': this.video,
                'canvas': this.canvas,
                'frameInterval': this.frameInterval || 10,
                'disableLogs': this.disableLogs,
                'recorderType': recorderType,
                'mimeType': mimeType.video,
                'timeSlice': this.timeSlice,
                'onTimeStamp': this.onTimeStamp,
                'workerPath': this.workerPath,
                'webAssemblyPath': this.webAssemblyPath,
                'frameRate': this.frameRate,
                'bitrate': this.bitrate
            }), mediaType.audio || this.videoRecorder.startRecording();
        }
        if (mediaType.audio && mediaType.video) {
            self = this, videoTrack = !0 === isMediaRecorderCompatible();
            !0 === (videoTrack = mediaType.audio instanceof StereoAudioRecorder && mediaType.video || !0 !== mediaType.audio && !0 !== mediaType.video && mediaType.audio !== mediaType.video ? !1 : videoTrack) ? (self.audioRecorder = null, 
            self.videoRecorder.startRecording()) : self.videoRecorder.initRecorder(function() {
                self.audioRecorder.initRecorder(function() {
                    self.videoRecorder.startRecording(), self.audioRecorder.startRecording();
                });
            });
        }
        mediaType.gif && (recorderType = null, 'function' == typeof mediaType.gif && (recorderType = mediaType.gif), 
        this.gifRecorder = new RecordRTC(mediaStream, {
            'type': 'gif',
            'frameRate': this.frameRate || 200,
            'quality': this.quality || 10,
            'disableLogs': this.disableLogs,
            'recorderType': recorderType,
            'mimeType': mimeType.gif
        }), this.gifRecorder.startRecording());
    }, this.stopRecording = function(callback) {
        callback = callback || function() {}, this.audioRecorder && this.audioRecorder.stopRecording(function(blobURL) {
            callback(blobURL, 'audio');
        }), this.videoRecorder && this.videoRecorder.stopRecording(function(blobURL) {
            callback(blobURL, 'video');
        }), this.gifRecorder && this.gifRecorder.stopRecording(function(blobURL) {
            callback(blobURL, 'gif');
        });
    }, this.pauseRecording = function() {
        this.audioRecorder && this.audioRecorder.pauseRecording(), this.videoRecorder && this.videoRecorder.pauseRecording(), 
        this.gifRecorder && this.gifRecorder.pauseRecording();
    }, this.resumeRecording = function() {
        this.audioRecorder && this.audioRecorder.resumeRecording(), this.videoRecorder && this.videoRecorder.resumeRecording(), 
        this.gifRecorder && this.gifRecorder.resumeRecording();
    }, this.getBlob = function(callback) {
        var output = {};
        return this.audioRecorder && (output.audio = this.audioRecorder.getBlob()), 
        this.videoRecorder && (output.video = this.videoRecorder.getBlob()), this.gifRecorder && (output.gif = this.gifRecorder.getBlob()), 
        callback && callback(output), output;
    }, this.destroy = function() {
        this.audioRecorder && (this.audioRecorder.destroy(), this.audioRecorder = null), 
        this.videoRecorder && (this.videoRecorder.destroy(), this.videoRecorder = null), 
        this.gifRecorder && (this.gifRecorder.destroy(), this.gifRecorder = null);
    }, this.getDataURL = function(callback) {
        function getDataURL(blob, callback00) {
            var webWorker;
            'undefined' != typeof Worker ? ((webWorker = function(_function) {
                var url, _function = URL.createObjectURL(new Blob([ _function.toString(), 'this.onmessage =  function (eee) {' + _function.name + '(eee.data);}' ], {
                    'type': 'application/javascript'
                })), worker = new Worker(_function);
                if (void 0 !== URL) url = URL; else {
                    if ('undefined' == typeof webkitURL) throw 'Neither URL nor webkitURL detected.';
                    url = webkitURL;
                }
                return url.revokeObjectURL(_function), worker;
            }(function(_blob) {
                postMessage(new FileReaderSync().readAsDataURL(_blob));
            })).onmessage = function(event) {
                callback00(event.data);
            }, webWorker.postMessage(blob)) : ((webWorker = new FileReader()).readAsDataURL(blob), 
            webWorker.onload = function(event) {
                callback00(event.target.result);
            });
        }
        this.getBlob(function(blob) {
            blob.audio && blob.video ? getDataURL(blob.audio, function(_audioDataURL) {
                getDataURL(blob.video, function(_videoDataURL) {
                    callback({
                        'audio': _audioDataURL,
                        'video': _videoDataURL
                    });
                });
            }) : blob.audio ? getDataURL(blob.audio, function(_audioDataURL) {
                callback({
                    'audio': _audioDataURL
                });
            }) : blob.video && getDataURL(blob.video, function(_videoDataURL) {
                callback({
                    'video': _videoDataURL
                });
            });
        });
    }, this.writeToDisk = function() {
        RecordRTC.writeToDisk({
            'audio': this.audioRecorder,
            'video': this.videoRecorder,
            'gif': this.gifRecorder
        });
    }, this.save = function(args) {
        (args = args || {
            'audio': !0,
            'video': !0,
            'gif': !0
        }).audio && this.audioRecorder && this.audioRecorder.save('string' == typeof args.audio ? args.audio : ''), 
        args.video && this.videoRecorder && this.videoRecorder.save('string' == typeof args.video ? args.video : ''), 
        args.gif && this.gifRecorder && this.gifRecorder.save('string' == typeof args.gif ? args.gif : '');
    };
}

function bytesToSize(bytes) {
    var sizes, i;
    sizes = [ 'Bytes', 'KB', 'MB', 'GB', 'TB' ];
    if (0 === bytes) return '0 Bytes';
    i = parseInt(Math.floor(Math.log(bytes) / Math.log(1e3)), 10);
    return (bytes / Math.pow(1e3, i)).toPrecision(3) + ' ' + sizes[i];
}

function invokeSaveAsDialog(file, fileName) {
    var fileExtension, splitted;
    if (!file) throw 'Blob object is required.';
    if (!file.type) try {
        file.type = 'video/webm';
    } catch (e) {}
    fileExtension = (file.type || 'video/webm').split('/')[1];
    fileName && -1 !== fileName.indexOf('.') && (fileName = (splitted = fileName.split('.'))[0], 
    fileExtension = splitted[1]);
    splitted = (fileName || Math.round(9999999999 * Math.random()) + 888888888) + '.' + fileExtension;
    if (void 0 !== navigator.msSaveOrOpenBlob) return navigator.msSaveOrOpenBlob(file, splitted);
    if (void 0 !== navigator.msSaveBlob) return navigator.msSaveBlob(file, splitted);
    (fileName = document.createElement('a')).href = URL.createObjectURL(file), fileName.download = splitted, 
    fileName.style = 'display:none;opacity:0;color:transparent;', (document.body || document.documentElement).appendChild(fileName), 
    'function' == typeof fileName.click ? fileName.click() : (fileName.target = '_blank', 
    fileName.dispatchEvent(new MouseEvent('click', {
        'view': window,
        'bubbles': !0,
        'cancelable': !0
    }))), URL.revokeObjectURL(fileName.href);
}

function isElectron() {
    return 'undefined' != typeof window && 'object' == typeof window.process && 'renderer' === window.process.type || !('undefined' == typeof process || 'object' != typeof process.versions || !process.versions.electron) || 'object' == typeof navigator && 'string' == typeof navigator.userAgent && 0 <= navigator.userAgent.indexOf('Electron');
}

function getTracks(stream, kind) {
    return stream && stream.getTracks ? stream.getTracks().filter(function(t) {
        return t.kind === (kind || 'audio');
    }) : [];
}

function setSrcObject(stream, element) {
    !('srcObject' in element) && 'mozSrcObject' in element ? element.mozSrcObject = stream : element.srcObject = stream;
}

function getSeekableBlob(inputBlob, callback) {
    if ('undefined' == typeof EBML) throw new Error('Please link: https://www.webrtc-experiment.com/EBML.js');
    var reader = new EBML.Reader(), decoder = new EBML.Decoder(), tools = EBML.tools, fileReader = new FileReader();
    fileReader.onload = function(e) {
        var body, refinedMetadataBuf;
        decoder.decode(this.result).forEach(function(element) {
            reader.read(element);
        }), reader.stop();
        refinedMetadataBuf = tools.makeMetadataSeekable(reader.metadatas, reader.duration, reader.cues), 
        body = this.result.slice(reader.metadataSize), refinedMetadataBuf = new Blob([ refinedMetadataBuf, body ], {
            'type': 'video/webm'
        });
        callback(refinedMetadataBuf);
    }, fileReader.readAsArrayBuffer(inputBlob);
}

function isMediaRecorderCompatible() {
    if (isFirefox || isSafari || isEdge) return !0;
    navigator.appVersion;
    var verOffset, nAgt = navigator.userAgent, fullVersion = '' + parseFloat(navigator.appVersion), majorVersion = parseInt(navigator.appVersion, 10);
    return (isChrome || isOpera) && (verOffset = nAgt.indexOf('Chrome'), fullVersion = nAgt.substring(verOffset + 7)), 
    -1 !== (nAgt = (fullVersion = -1 !== (nAgt = fullVersion.indexOf(';')) ? fullVersion.substring(0, nAgt) : fullVersion).indexOf(' ')) && (fullVersion = fullVersion.substring(0, nAgt)), 
    majorVersion = parseInt('' + fullVersion, 10), isNaN(majorVersion) && (fullVersion = '' + parseFloat(navigator.appVersion), 
    majorVersion = parseInt(navigator.appVersion, 10)), 49 <= majorVersion;
}

function MediaStreamRecorder(mediaStream, config) {
    var self, stream, arrayOfBlobs, mediaRecorder, allStates;
    function updateTimeStamp() {
        self.timestamps.push(new Date().getTime()), 'function' == typeof config.onTimeStamp && config.onTimeStamp(self.timestamps[self.timestamps.length - 1], self.timestamps);
    }
    function getMimeType(secondObject) {
        return mediaRecorder && mediaRecorder.mimeType ? mediaRecorder.mimeType : secondObject.mimeType || 'video/webm';
    }
    function clearRecordedDataCB() {
        arrayOfBlobs = [], mediaRecorder = null, self.timestamps = [];
    }
    self = this;
    if (void 0 === mediaStream) throw 'First argument "MediaStream" is required.';
    if ('undefined' == typeof MediaRecorder) throw 'Your browser does not support the Media Recorder API. Please try other modules e.g. WhammyRecorder or StereoAudioRecorder.';
    if ('audio' === (config = config || {
        'mimeType': 'video/webm'
    }).type) {
        getTracks(mediaStream, 'video').length && getTracks(mediaStream, 'audio').length && (navigator.mozGetUserMedia ? (stream = new MediaStream()).addTrack(getTracks(mediaStream, 'audio')[0]) : stream = new MediaStream(getTracks(mediaStream, 'audio')), 
        mediaStream = stream);
        config.mimeType && -1 !== config.mimeType.toString().toLowerCase().indexOf('audio') || (config.mimeType = isChrome ? 'audio/webm' : 'audio/ogg'), 
        config.mimeType && 'audio/ogg' !== config.mimeType.toString().toLowerCase() && navigator.mozGetUserMedia && (config.mimeType = 'audio/ogg');
    }
    arrayOfBlobs = [];
    this.getArrayOfBlobs = function() {
        return arrayOfBlobs;
    }, this.record = function() {
        self.blob = null, self.clearRecordedData(), self.timestamps = [], allStates = [], 
        arrayOfBlobs = [];
        var recorderHints = config;
        config.disableLogs, mediaRecorder = mediaRecorder && null, isChrome && !isMediaRecorderCompatible() && (recorderHints = 'video/vp8'), 
        'function' != typeof MediaRecorder.isTypeSupported || !recorderHints.mimeType || MediaRecorder.isTypeSupported(recorderHints.mimeType) || (config.disableLogs, 
        recorderHints.mimeType = 'audio' === config.type ? 'audio/webm' : 'video/webm');
        try {
            mediaRecorder = new MediaRecorder(mediaStream, recorderHints), config.mimeType = recorderHints.mimeType;
        } catch (e) {
            mediaRecorder = new MediaRecorder(mediaStream);
        }
        recorderHints.mimeType && !MediaRecorder.isTypeSupported && 'canRecordMimeType' in mediaRecorder && !1 === mediaRecorder.canRecordMimeType(recorderHints.mimeType) && config.disableLogs, 
        mediaRecorder.ondataavailable = function(e) {
            if (e.data && allStates.push('ondataavailable: ' + bytesToSize(e.data.size)), 
            'number' != typeof config.timeSlice) {
                if (!e.data || !e.data.size || e.data.size < 100 || self.blob) return void (self.recordingCallback && (self.recordingCallback(new Blob([], {
                    'type': getMimeType(recorderHints)
                })), self.recordingCallback = null));
                self.blob = config.getNativeBlob ? e.data : new Blob([ e.data ], {
                    'type': getMimeType(recorderHints)
                }), self.recordingCallback && (self.recordingCallback(self.blob), 
                self.recordingCallback = null);
            } else if (e.data && e.data.size && 100 < e.data.size && (arrayOfBlobs.push(e.data), 
            updateTimeStamp(), 'function' == typeof config.ondataavailable)) {
                e = config.getNativeBlob ? e.data : new Blob([ e.data ], {
                    'type': getMimeType(recorderHints)
                });
                config.ondataavailable(e);
            }
        }, mediaRecorder.onstart = function() {
            allStates.push('started');
        }, mediaRecorder.onpause = function() {
            allStates.push('paused');
        }, mediaRecorder.onresume = function() {
            allStates.push('resumed');
        }, mediaRecorder.onstop = function() {
            allStates.push('stopped');
        }, mediaRecorder.onerror = function(error) {
            error && (error.name || (error.name = 'UnknownError'), allStates.push('error: ' + error), 
            config.disableLogs || -1 === error.name.toString().toLowerCase().indexOf('invalidstate') && -1 === error.name.toString().toLowerCase().indexOf('notsupported') && -1 === error.name.toString().toLowerCase().indexOf('security') && 'OutOfMemory' !== error.name && 'IllegalStreamModification' !== error.name && 'OtherRecordingError' !== error.name && error.name, 
            !self.manuallyStopped && mediaRecorder && 'inactive' === mediaRecorder.state ? (delete config.timeslice, 
            mediaRecorder.start(6e5)) : setTimeout(void 0, 1e3), 'inactive' !== mediaRecorder.state) && 'stopped' !== mediaRecorder.state && mediaRecorder.stop();
        }, 'number' == typeof config.timeSlice ? (updateTimeStamp(), mediaRecorder.start(config.timeSlice)) : mediaRecorder.start(36e5), 
        config.initCallback && config.initCallback();
    }, this.timestamps = [], this.stop = function(callback) {
        callback = callback || function() {}, self.manuallyStopped = !0, mediaRecorder && (this.recordingCallback = callback, 
        'recording' === mediaRecorder.state && mediaRecorder.stop(), 'number' == typeof config.timeSlice) && setTimeout(function() {
            self.blob = new Blob(arrayOfBlobs, {
                'type': getMimeType(config)
            }), self.recordingCallback(self.blob);
        }, 100);
    }, this.pause = function() {
        mediaRecorder && 'recording' === mediaRecorder.state && mediaRecorder.pause();
    }, this.resume = function() {
        mediaRecorder && 'paused' === mediaRecorder.state && mediaRecorder.resume();
    }, this.clearRecordedData = function() {
        mediaRecorder && 'recording' === mediaRecorder.state && self.stop(clearRecordedDataCB), 
        clearRecordedDataCB();
    };
    this.getInternalRecorder = function() {
        return mediaRecorder;
    }, this.blob = null, this.getState = function() {
        return mediaRecorder && mediaRecorder.state || 'inactive';
    };
    allStates = [];
    this.getAllStates = function() {
        return allStates;
    }, void 0 === config.checkForInactiveTracks && (config.checkForInactiveTracks = !1);
    self = this;
    !function looper() {
        if (mediaRecorder && !1 !== config.checkForInactiveTracks) return !1 === function() {
            if ('active' in mediaStream) {
                if (!mediaStream.active) return !1;
            } else if ('ended' in mediaStream && mediaStream.ended) return !1;
            return !0;
        }() ? (config.disableLogs, void self.stop()) : void setTimeout(looper, 1e3);
    }(), this.name = 'MediaStreamRecorder', this.toString = function() {
        return this.name;
    };
}

function StereoAudioRecorder(mediaStream, config) {
    var jsAudioNode, self, leftchannel, rightchannel, recording, recordingLength, numberOfAudioChannels, desiredSampRate, context, audioInput, bufferSize, sampleRate, isPaused, isAudioProcessStarted, intervalsBasedBuffers;
    function isMediaStreamActive() {
        if (!1 === config.checkForInactiveTracks) return !0;
        if ('active' in mediaStream) {
            if (!mediaStream.active) return !1;
        } else if ('ended' in mediaStream && mediaStream.ended) return !1;
        return !0;
    }
    function mergeLeftRightBuffers(config, callback) {
        function mergeAudioBuffers(config, cb) {
            var numberOfAudioChannels, leftBuffers, rightBuffers, sampleRate, interleaved, internalInterleavedLength, view, lng, index, i;
            function interpolateArray(data, newSampleRate, oldSampleRate) {
                var fitCount, newData, springFactor, i, tmp, before, after;
                fitCount = Math.round(data.length * (newSampleRate / oldSampleRate)), 
                newData = [], springFactor = Number((data.length - 1) / (fitCount - 1));
                newData[0] = data[0];
                for (i = 1; i < fitCount - 1; i++) {
                    tmp = i * springFactor, before = Number(Math.floor(tmp)).toFixed(), 
                    after = Number(Math.ceil(tmp)).toFixed();
                    newData[i] = function(before, after, atPoint) {
                        return before + (after - before) * atPoint;
                    }(data[before], data[after], tmp - before);
                }
                return newData[fitCount - 1] = data[data.length - 1], newData;
            }
            function mergeBuffers(channelBuffer, rLength) {
                var result, offset, lng, i, buffer;
                for (result = new Float64Array(rLength), lng = channelBuffer.length, 
                i = offset = 0; i < lng; i++) {
                    buffer = channelBuffer[i];
                    result.set(buffer, offset), offset += buffer.length;
                }
                return result;
            }
            function writeUTFBytes(view, offset, string) {
                for (var lng = string.length, i = 0; i < lng; i++) view.setUint8(offset + i, string.charCodeAt(i));
            }
            numberOfAudioChannels = config.numberOfAudioChannels, leftBuffers = config.leftBuffers.slice(0), 
            rightBuffers = config.rightBuffers.slice(0), sampleRate = config.sampleRate, 
            internalInterleavedLength = config.internalInterleavedLength, config = config.desiredSampRate;
            2 === numberOfAudioChannels && (leftBuffers = mergeBuffers(leftBuffers, internalInterleavedLength), 
            rightBuffers = mergeBuffers(rightBuffers, internalInterleavedLength), 
            config) && (leftBuffers = interpolateArray(leftBuffers, config, sampleRate), 
            rightBuffers = interpolateArray(rightBuffers, config, sampleRate)), 
            1 === numberOfAudioChannels && (leftBuffers = mergeBuffers(leftBuffers, internalInterleavedLength), 
            config) && (leftBuffers = interpolateArray(leftBuffers, config, sampleRate)), 
            config && (sampleRate = config);
            2 === numberOfAudioChannels && (interleaved = function(leftChannel, rightChannel) {
                for (var length = leftChannel.length + rightChannel.length, result = new Float64Array(length), inputIndex = 0, index = 0; index < length; ) result[index++] = leftChannel[inputIndex], 
                result[index++] = rightChannel[inputIndex], inputIndex++;
                return result;
            }(leftBuffers, rightBuffers));
            internalInterleavedLength = (interleaved = 1 === numberOfAudioChannels ? leftBuffers : interleaved).length, 
            config = new ArrayBuffer(44 + 2 * internalInterleavedLength);
            writeUTFBytes(view = new DataView(config), 0, 'RIFF'), view.setUint32(4, 36 + 2 * internalInterleavedLength, !0), 
            writeUTFBytes(view, 8, 'WAVE'), writeUTFBytes(view, 12, 'fmt '), view.setUint32(16, 16, !0), 
            view.setUint16(20, 1, !0), view.setUint16(22, numberOfAudioChannels, !0), 
            view.setUint32(24, sampleRate, !0), view.setUint32(28, 2 * sampleRate, !0), 
            view.setUint16(32, 2 * numberOfAudioChannels, !0), view.setUint16(34, 16, !0), 
            writeUTFBytes(view, 36, 'data'), view.setUint32(40, 2 * internalInterleavedLength, !0);
            for (lng = internalInterleavedLength, index = 44, i = 0; i < lng; i++) view.setInt16(index, 32767 * interleaved[i], !0), 
            index += 2;
            return cb ? cb({
                'buffer': config,
                'view': view
            }) : void postMessage({
                'buffer': config,
                'view': view
            });
        }
        if (config.noWorker) return mergeAudioBuffers(config, function(data) {
            callback(data.buffer, data.view);
        });
        _function = mergeAudioBuffers, _function = URL.createObjectURL(new Blob([ _function.toString(), ';this.onmessage =  function (eee) {' + _function.name + '(eee.data);}' ], {
            'type': 'application/javascript'
        })), (worker = new Worker(_function)).workerURL = _function;
        var webWorker = worker;
        var _function, worker;
        webWorker.onmessage = function(event) {
            callback(event.data.buffer, event.data.view), URL.revokeObjectURL(webWorker.workerURL), 
            webWorker.terminate();
        }, webWorker.postMessage(config);
    }
    function resetVariables() {
        leftchannel = [], recordingLength = 0, isPaused = recording = isAudioProcessStarted = !(rightchannel = []), 
        context = null, self.leftchannel = leftchannel, self.rightchannel = rightchannel, 
        self.numberOfAudioChannels = numberOfAudioChannels, self.desiredSampRate = desiredSampRate, 
        self.sampleRate = sampleRate, self.recordingLength = recordingLength, intervalsBasedBuffers = {
            'left': [],
            'right': [],
            'recordingLength': 0
        };
    }
    function clearRecordedDataCB() {
        jsAudioNode && (jsAudioNode.onaudioprocess = null, jsAudioNode.disconnect(), 
        jsAudioNode = null), audioInput && (audioInput.disconnect(), audioInput = null), 
        resetVariables();
    }
    function looper() {
        recording && 'function' == typeof config.ondataavailable && void 0 !== config.timeSlice && (intervalsBasedBuffers.left.length ? (mergeLeftRightBuffers({
            'desiredSampRate': desiredSampRate,
            'sampleRate': sampleRate,
            'numberOfAudioChannels': numberOfAudioChannels,
            'internalInterleavedLength': intervalsBasedBuffers.recordingLength,
            'leftBuffers': intervalsBasedBuffers.left,
            'rightBuffers': 1 === numberOfAudioChannels ? [] : intervalsBasedBuffers.right
        }, function(buffer, view) {
            view = new Blob([ view ], {
                'type': 'audio/wav'
            });
            config.ondataavailable(view), setTimeout(looper, config.timeSlice);
        }), intervalsBasedBuffers = {
            'left': [],
            'right': [],
            'recordingLength': 0
        }) : setTimeout(looper, config.timeSlice));
    }
    if (!getTracks(mediaStream, 'audio').length) throw 'Your stream has no audio tracks.';
    self = this, leftchannel = [], recording = !(rightchannel = []), recordingLength = 0, 
    numberOfAudioChannels = 2, desiredSampRate = (config = config || {}).desiredSampRate;
    !0 === config.leftChannel && (numberOfAudioChannels = 1), (!(numberOfAudioChannels = 1 === config.numberOfAudioChannels ? 1 : numberOfAudioChannels) || numberOfAudioChannels < 1) && (numberOfAudioChannels = 2), 
    config.disableLogs, void 0 === config.checkForInactiveTracks && (config.checkForInactiveTracks = !0), 
    this.record = function() {
        if (!1 === isMediaStreamActive()) throw 'Please make sure MediaStream is active.';
        resetVariables(), isAudioProcessStarted = isPaused = !1, recording = !0, 
        void 0 !== config.timeSlice && looper();
    }, this.stop = function(callback) {
        callback = callback || function() {}, recording = !1, mergeLeftRightBuffers({
            'desiredSampRate': desiredSampRate,
            'sampleRate': sampleRate,
            'numberOfAudioChannels': numberOfAudioChannels,
            'internalInterleavedLength': recordingLength,
            'leftBuffers': leftchannel,
            'rightBuffers': 1 === numberOfAudioChannels ? [] : rightchannel,
            'noWorker': config.noWorker
        }, function(buffer, view) {
            self.blob = new Blob([ view ], {
                'type': 'audio/wav'
            }), self.buffer = new ArrayBuffer(view.buffer.byteLength), self.view = view, 
            self.sampleRate = desiredSampRate || sampleRate, self.bufferSize = bufferSize, 
            self.length = recordingLength, isAudioProcessStarted = !1, callback && callback(self.blob);
        });
    }, void 0 === RecordRTC.Storage && (RecordRTC.Storage = {
        'AudioContextConstructor': null,
        'AudioContext': window.AudioContext || window.webkitAudioContext
    }), RecordRTC.Storage.AudioContextConstructor && 'closed' !== RecordRTC.Storage.AudioContextConstructor.state || (RecordRTC.Storage.AudioContextConstructor = new RecordRTC.Storage.AudioContext());
    context = RecordRTC.Storage.AudioContextConstructor, audioInput = context.createMediaStreamSource(mediaStream), 
    bufferSize = void 0 === config.bufferSize ? 4096 : config.bufferSize;
    if (-1 === [ 0, 256, 512, 1024, 2048, 4096, 8192, 16384 ].indexOf(bufferSize) && config.disableLogs, 
    context.createJavaScriptNode) jsAudioNode = context.createJavaScriptNode(bufferSize, numberOfAudioChannels, numberOfAudioChannels); else {
        if (!context.createScriptProcessor) throw 'WebAudio API has no support on this browser.';
        jsAudioNode = context.createScriptProcessor(bufferSize, numberOfAudioChannels, numberOfAudioChannels);
    }
    audioInput.connect(jsAudioNode), config.bufferSize || (bufferSize = jsAudioNode.bufferSize);
    ((sampleRate = void 0 !== config.sampleRate ? config.sampleRate : context.sampleRate || 44100) < 22050 || 96e3 < sampleRate) && config.disableLogs, 
    config.disableLogs || config.desiredSampRate;
    isPaused = !1;
    this.pause = function() {
        isPaused = !0;
    }, this.resume = function() {
        if (!1 === isMediaStreamActive()) throw 'Please make sure MediaStream is active.';
        return recording ? void (isPaused = !1) : (config.disableLogs, void this.record());
    }, this.clearRecordedData = function() {
        config.checkForInactiveTracks = !1, recording && this.stop(clearRecordedDataCB), 
        clearRecordedDataCB();
    }, this.name = 'StereoAudioRecorder', this.toString = function() {
        return this.name;
    };
    isAudioProcessStarted = !1;
    jsAudioNode.onaudioprocess = function(e) {
        var left, chRight;
        if (!isPaused) {
            if (!1 === isMediaStreamActive() && (config.disableLogs, jsAudioNode.disconnect(), 
            recording = !1), !recording) return void (audioInput && (audioInput.disconnect(), 
            audioInput = null));
            isAudioProcessStarted || (isAudioProcessStarted = !0, config.onAudioProcessStarted && config.onAudioProcessStarted(), 
            config.initCallback && config.initCallback());
            left = e.inputBuffer.getChannelData(0), left = new Float32Array(left);
            if (leftchannel.push(left), 2 === numberOfAudioChannels) {
                e = e.inputBuffer.getChannelData(1), chRight = new Float32Array(e);
                rightchannel.push(chRight);
            }
            recordingLength += bufferSize, self.recordingLength = recordingLength, 
            void 0 !== config.timeSlice && (intervalsBasedBuffers.recordingLength += bufferSize, 
            intervalsBasedBuffers.left.push(left), 2 === numberOfAudioChannels) && intervalsBasedBuffers.right.push(chRight);
        }
    }, context.createMediaStreamDestination ? jsAudioNode.connect(context.createMediaStreamDestination()) : jsAudioNode.connect(context.destination), 
    this.leftchannel = leftchannel, this.rightchannel = rightchannel, this.numberOfAudioChannels = numberOfAudioChannels, 
    this.desiredSampRate = desiredSampRate, this.sampleRate = sampleRate, self.recordingLength = recordingLength;
    intervalsBasedBuffers = {
        'left': [],
        'right': [],
        'recordingLength': 0
    };
}

function CanvasRecorder(htmlElement, config) {
    var isCanvasSupportsStreamCapturing, _isChrome, chromeVersion, matchArray, globalCanvas, mediaStreamRecorder, isRecording, isPausedRecording, lastTime, whammy;
    function clearRecordedDataCB() {
        whammy.frames = [], isPausedRecording = isRecording = !1;
    }
    function drawCanvasFrame() {
        if (isPausedRecording) return lastTime = new Date().getTime(), setTimeout(drawCanvasFrame, 500);
        var duration;
        if ('canvas' === htmlElement.nodeName.toLowerCase()) return duration = new Date().getTime() - lastTime, 
        lastTime = new Date().getTime(), whammy.frames.push({
            'image': (newCanvas = document.createElement('canvas'), context = newCanvas.getContext('2d'), 
            newCanvas.width = htmlElement.width, newCanvas.height = htmlElement.height, 
            context.drawImage(htmlElement, 0, 0), newCanvas),
            'duration': duration
        }), void (isRecording && setTimeout(drawCanvasFrame, config.frameInterval));
        var newCanvas, context;
        html2canvas(htmlElement, {
            'grabMouse': void 0 === config.showMousePointer || config.showMousePointer,
            'onrendered': function(canvas) {
                var duration = new Date().getTime() - lastTime;
                return duration ? (lastTime = new Date().getTime(), whammy.frames.push({
                    'image': canvas.toDataURL('image/webp', 1),
                    'duration': duration
                }), void (isRecording && setTimeout(drawCanvasFrame, config.frameInterval))) : setTimeout(drawCanvasFrame, config.frameInterval);
            }
        });
    }
    if ('undefined' == typeof html2canvas) throw 'Please link: https://www.webrtc-experiment.com/screenshot.js';
    (config = config || {}).frameInterval || (config.frameInterval = 10);
    isCanvasSupportsStreamCapturing = !1;
    [ 'captureStream', 'mozCaptureStream', 'webkitCaptureStream' ].forEach(function(item) {
        item in document.createElement('canvas') && (isCanvasSupportsStreamCapturing = !0);
    });
    _isChrome = !(!window.webkitRTCPeerConnection && !window.webkitGetUserMedia || !window.chrome), 
    chromeVersion = 50, matchArray = navigator.userAgent.match(/Chrom(e|ium)\/([0-9]+)\./);
    _isChrome && matchArray && matchArray[2] && (chromeVersion = parseInt(matchArray[2], 10)), 
    _isChrome && chromeVersion < 52 && (isCanvasSupportsStreamCapturing = !1);
    if (isCanvasSupportsStreamCapturing = config.useWhammyRecorder ? !1 : isCanvasSupportsStreamCapturing) if (config.disableLogs, 
    htmlElement instanceof HTMLCanvasElement) globalCanvas = htmlElement; else {
        if (!(htmlElement instanceof CanvasRenderingContext2D)) throw 'Please pass either HTMLCanvasElement or CanvasRenderingContext2D.';
        globalCanvas = htmlElement.canvas;
    } else navigator.mozGetUserMedia && config.disableLogs;
    this.record = function() {
        var canvasMediaStream, mdStream;
        if (isRecording = !0, isCanvasSupportsStreamCapturing && !config.useWhammyRecorder) {
            'captureStream' in globalCanvas ? canvasMediaStream = globalCanvas.captureStream(25) : 'mozCaptureStream' in globalCanvas ? canvasMediaStream = globalCanvas.mozCaptureStream(25) : 'webkitCaptureStream' in globalCanvas && (canvasMediaStream = globalCanvas.webkitCaptureStream(25));
            try {
                (mdStream = new MediaStream()).addTrack(getTracks(canvasMediaStream, 'video')[0]), 
                canvasMediaStream = mdStream;
            } catch (e) {}
            if (!canvasMediaStream) throw 'captureStream API are NOT available.';
            (mediaStreamRecorder = new MediaStreamRecorder(canvasMediaStream, {
                'mimeType': config.mimeType || 'video/webm'
            })).record();
        } else whammy.frames = [], lastTime = new Date().getTime(), drawCanvasFrame();
        config.initCallback && config.initCallback();
    }, this.getWebPImages = function(callback) {
        if ('canvas' !== htmlElement.nodeName.toLowerCase()) return void callback();
        var framesLength = whammy.frames.length;
        whammy.frames.forEach(function(frame, idx) {
            var framesRemaining;
            framesRemaining = framesLength - idx;
            config.disableLogs, config.onEncodingCallback && config.onEncodingCallback(framesRemaining, framesLength);
            framesRemaining = frame.image.toDataURL('image/webp', 1);
            whammy.frames[idx].image = framesRemaining;
        }), config.disableLogs, callback();
    }, this.stop = function(callback) {
        isRecording = !1;
        var that = this;
        return isCanvasSupportsStreamCapturing && mediaStreamRecorder ? void mediaStreamRecorder.stop(callback) : void this.getWebPImages(function() {
            whammy.compile(function(blob) {
                config.disableLogs, that.blob = blob, that.blob.forEach && (that.blob = new Blob([], {
                    'type': 'video/webm'
                })), callback && callback(that.blob), whammy.frames = [];
            });
        });
    };
    isPausedRecording = !1;
    this.pause = function() {
        if (isPausedRecording = !0, mediaStreamRecorder instanceof MediaStreamRecorder) return void mediaStreamRecorder.pause();
    }, this.resume = function() {
        return isPausedRecording = !1, mediaStreamRecorder instanceof MediaStreamRecorder ? void mediaStreamRecorder.resume() : void (isRecording || this.record());
    }, this.clearRecordedData = function() {
        isRecording && this.stop(clearRecordedDataCB), clearRecordedDataCB();
    }, this.name = 'CanvasRecorder', this.toString = function() {
        return this.name;
    };
    lastTime = new Date().getTime(), whammy = new Whammy.Video(100);
}

function WhammyRecorder(mediaStream, config) {
    var isStopDrawing, isPausedRecording, video, lastTime, whammy, canvas, context;
    function drawFrames(frameInterval) {
        frameInterval = void 0 !== frameInterval ? frameInterval : 10;
        var duration = new Date().getTime() - lastTime;
        return duration ? isPausedRecording ? (lastTime = new Date().getTime(), 
        setTimeout(drawFrames, 100)) : (lastTime = new Date().getTime(), video.paused && video.play(), 
        context.drawImage(video, 0, 0, canvas.width, canvas.height), whammy.frames.push({
            'duration': duration,
            'image': canvas.toDataURL('image/webp')
        }), void (isStopDrawing || setTimeout(drawFrames, frameInterval, frameInterval))) : setTimeout(drawFrames, frameInterval, frameInterval);
    }
    function dropBlackFrames(_frames, _framesToCheck, _pixTolerance, _frameTolerance, callback) {
        var localCanvas, context2d, resultFrames, checkUntilNotBlack, endCheckFrame, sampleColor_r, sampleColor_g, sampleColor_b, maxColorDifference, pixTolerance, frameTolerance, doNotCheckNext;
        (localCanvas = document.createElement('canvas')).width = canvas.width, localCanvas.height = canvas.height;
        context2d = localCanvas.getContext('2d'), resultFrames = [], checkUntilNotBlack = -1 === _framesToCheck, 
        endCheckFrame = _framesToCheck && 0 < _framesToCheck && _framesToCheck <= _frames.length ? _framesToCheck : _frames.length, 
        sampleColor_b = sampleColor_g = sampleColor_r = 0, maxColorDifference = Math.sqrt(Math.pow(255, 2) + Math.pow(255, 2) + Math.pow(255, 2)), 
        pixTolerance = _pixTolerance && 0 <= _pixTolerance && _pixTolerance <= 1 ? _pixTolerance : 0, 
        frameTolerance = _frameTolerance && 0 <= _frameTolerance && _frameTolerance <= 1 ? _frameTolerance : 0, 
        doNotCheckNext = !1;
        i = -1, length = (o = {
            'length': endCheckFrame,
            'functionToLoop': function(loop, f) {
                var matchPixCount, endPixCheck, maxPixCount, finishImage, image;
                finishImage = function() {
                    !doNotCheckNext && maxPixCount - matchPixCount <= maxPixCount * frameTolerance || (checkUntilNotBlack && (doNotCheckNext = !0), 
                    resultFrames.push(_frames[f])), loop();
                };
                doNotCheckNext ? finishImage() : ((image = new Image()).onload = function() {
                    var imageData, pix, currentColor_r, currentColor_g, currentColor_b;
                    context2d.drawImage(image, 0, 0, canvas.width, canvas.height);
                    imageData = context2d.getImageData(0, 0, canvas.width, canvas.height);
                    matchPixCount = 0, endPixCheck = imageData.data.length, maxPixCount = imageData.data.length / 4;
                    for (pix = 0; pix < endPixCheck; pix += 4) {
                        currentColor_r = imageData.data[pix], currentColor_g = imageData.data[pix + 1], 
                        currentColor_b = imageData.data[pix + 2];
                        Math.sqrt(Math.pow(currentColor_r - sampleColor_r, 2) + Math.pow(currentColor_g - sampleColor_g, 2) + Math.pow(currentColor_b - sampleColor_b, 2)) <= maxColorDifference * pixTolerance && matchPixCount++;
                    }
                    finishImage();
                }, image.src = _frames[f].image);
            },
            'callback': function() {
                (resultFrames = resultFrames.concat(_frames.slice(endCheckFrame))).length <= 0 && resultFrames.push(_frames[_frames.length - 1]), 
                callback(resultFrames);
            }
        }).length, function loop() {
            return ++i === length ? void o.callback() : void setTimeout(function() {
                o.functionToLoop(loop, i);
            }, 1);
        }();
        var o, i, length;
    }
    function clearRecordedDataCB() {
        whammy.frames = [], isPausedRecording = !(isStopDrawing = !0);
    }
    (config = config || {}).frameInterval || (config.frameInterval = 10), config.disableLogs, 
    this.record = function() {
        config.width || (config.width = 320), config.height || (config.height = 240), 
        config.video || (config.video = {
            'width': config.width,
            'height': config.height
        }), config.canvas || (config.canvas = {
            'width': config.width,
            'height': config.height
        }), canvas.width = config.canvas.width || 320, canvas.height = config.canvas.height || 240, 
        context = canvas.getContext('2d'), config.video && config.video instanceof HTMLVideoElement ? (video = config.video.cloneNode(), 
        config.initCallback && config.initCallback()) : (video = document.createElement('video'), 
        setSrcObject(mediaStream, video), video.onloadedmetadata = function() {
            config.initCallback && config.initCallback();
        }, video.width = config.video.width, video.height = config.video.height), 
        video.muted = !0, video.play(), lastTime = new Date().getTime(), whammy = new Whammy.Video(), 
        config.disableLogs, drawFrames(config.frameInterval);
    };
    isStopDrawing = !1;
    this.stop = function(callback) {
        callback = callback || function() {}, isStopDrawing = !0;
        var _this = this;
        setTimeout(function() {
            dropBlackFrames(whammy.frames, -1, null, null, function(frames) {
                whammy.frames = frames, config.advertisement && config.advertisement.length && (whammy.frames = config.advertisement.concat(whammy.frames)), 
                whammy.compile(function(blob) {
                    _this.blob = blob, _this.blob.forEach && (_this.blob = new Blob([], {
                        'type': 'video/webm'
                    })), callback && callback(_this.blob);
                });
            });
        }, 10);
    };
    isPausedRecording = !1;
    this.pause = function() {
        isPausedRecording = !0;
    }, this.resume = function() {
        isPausedRecording = !1, isStopDrawing && this.record();
    }, this.clearRecordedData = function() {
        isStopDrawing || this.stop(clearRecordedDataCB), clearRecordedDataCB();
    }, this.name = 'WhammyRecorder', this.toString = function() {
        return this.name;
    };
    canvas = document.createElement('canvas'), context = canvas.getContext('2d');
}

function GifRecorder(mediaStream, config) {
    var script, isHTMLObject, isPausedRecording, canvas, context, isLoadedMetaData, video, lastFrameTime, gifEncoder, lastAnimationFrame, self;
    'undefined' == typeof GIFEncoder && ((script = document.createElement('script')).src = 'https://www.webrtc-experiment.com/gif-recorder.js', 
    (document.body || document.documentElement).appendChild(script));
    config = config || {};
    isHTMLObject = mediaStream instanceof CanvasRenderingContext2D || mediaStream instanceof HTMLCanvasElement;
    this.record = function() {
        return 'undefined' != typeof GIFEncoder && isLoadedMetaData ? (isHTMLObject || (config.width || (config.width = video.offsetWidth || 320), 
        config.height || (config.height = video.offsetHeight || 240), config.video || (config.video = {
            'width': config.width,
            'height': config.height
        }), config.canvas || (config.canvas = {
            'width': config.width,
            'height': config.height
        }), canvas.width = config.canvas.width || 320, canvas.height = config.canvas.height || 240, 
        video.width = config.video.width || 320, video.height = config.video.height || 240), 
        (gifEncoder = new GIFEncoder()).setRepeat(0), gifEncoder.setDelay(config.frameRate || 200), 
        gifEncoder.setQuality(config.quality || 10), gifEncoder.start(), 'function' == typeof config.onGifRecordingStarted && config.onGifRecordingStarted(), 
        Date.now(), lastAnimationFrame = requestAnimationFrame(function drawVideoFrame(time) {
            if (!0 !== self.clearedRecordedData) {
                if (isPausedRecording) return setTimeout(function() {
                    drawVideoFrame(time);
                }, 100);
                lastAnimationFrame = requestAnimationFrame(drawVideoFrame), time - lastFrameTime < 90 || (!isHTMLObject && video.paused && video.play(), 
                isHTMLObject || context.drawImage(video, 0, 0, canvas.width, canvas.height), 
                config.onGifPreview && config.onGifPreview(canvas.toDataURL('image/png')), 
                gifEncoder.addFrame(context), lastFrameTime = time);
            }
        }), void (config.initCallback && config.initCallback())) : void setTimeout(self.record, 1e3);
    }, this.stop = function(callback) {
        callback = callback || function() {}, lastAnimationFrame && cancelAnimationFrame(lastAnimationFrame), 
        Date.now(), this.blob = new Blob([ new Uint8Array(gifEncoder.stream().bin) ], {
            'type': 'image/gif'
        }), callback(this.blob), gifEncoder.stream().bin = [];
    };
    isPausedRecording = !1;
    this.pause = function() {
        isPausedRecording = !0;
    }, this.resume = function() {
        isPausedRecording = !1;
    }, this.clearRecordedData = function() {
        self.clearedRecordedData = !0, gifEncoder && (gifEncoder.stream().bin = []);
    }, this.name = 'GifRecorder', this.toString = function() {
        return this.name;
    };
    canvas = document.createElement('canvas'), context = canvas.getContext('2d');
    isHTMLObject && (mediaStream instanceof CanvasRenderingContext2D ? canvas = (context = mediaStream).canvas : mediaStream instanceof HTMLCanvasElement && (context = mediaStream.getContext('2d'), 
    canvas = mediaStream));
    isLoadedMetaData = !0;
    isHTMLObject || ((video = document.createElement('video')).muted = !0, video.autoplay = !0, 
    video.playsInline = !0, isLoadedMetaData = !1, video.onloadedmetadata = function() {
        isLoadedMetaData = !0;
    }, setSrcObject(mediaStream, video), video.play());
    lastAnimationFrame = null, self = this;
}

function MultiStreamsMixer(arrayOfMediaStreams, elementClass) {
    var videos, isStopDrawingFrames, canvas, context, self, URL, MediaStream, Storage;
    function drawVideosToCanvas() {
        var videosLength, fullcanvas, remaining, height;
        if (!isStopDrawingFrames) {
            videosLength = videos.length, fullcanvas = !1, remaining = [];
            if (videos.forEach(function(video) {
                video.stream || (video.stream = {}), video.stream.fullcanvas ? fullcanvas = video : remaining.push(video);
            }), fullcanvas) canvas.width = fullcanvas.stream.width, canvas.height = fullcanvas.stream.height; else if (remaining.length) {
                canvas.width = 1 < videosLength ? 2 * remaining[0].width : remaining[0].width;
                height = 1;
                3 !== videosLength && 4 !== videosLength || (height = 2), 5 !== videosLength && 6 !== videosLength || (height = 3), 
                7 !== videosLength && 8 !== videosLength || (height = 4), canvas.height = remaining[0].height * (height = 9 !== videosLength && 10 !== videosLength ? height : 5);
            } else canvas.width = self.width || 360, canvas.height = self.height || 240;
            fullcanvas && fullcanvas instanceof HTMLVideoElement && drawImage(fullcanvas), 
            remaining.forEach(function(video, idx) {
                drawImage(video, idx);
            }), setTimeout(drawVideosToCanvas, self.frameInterval);
        }
    }
    function drawImage(video, idx) {
        if (!isStopDrawingFrames) {
            var x = 0, y = 0, width = video.width, height = video.height;
            1 === idx && (x = video.width), 2 === idx && (y = video.height), 3 === idx && (x = video.width, 
            y = video.height), 4 === idx && (y = 2 * video.height), 5 === idx && (x = video.width, 
            y = 2 * video.height), 6 === idx && (y = 3 * video.height), 7 === idx && (x = video.width, 
            y = 3 * video.height), void 0 !== video.stream.left && (x = video.stream.left), 
            void 0 !== video.stream.top && (y = video.stream.top), void 0 !== video.stream.width && (width = video.stream.width), 
            void 0 !== video.stream.height && (height = video.stream.height), context.drawImage(video, x, y, width, height), 
            'function' == typeof video.stream.onRender && video.stream.onRender(context, x, y, width, height, idx);
        }
    }
    function getVideo(stream) {
        var video = document.createElement('video');
        return function(stream, element) {
            !('srcObject' in element) && 'mozSrcObject' in element ? element.mozSrcObject = stream : element.srcObject = stream;
        }(stream, video), video.className = elementClass, video.muted = !0, video.volume = 0, 
        video.width = stream.width || self.width || 360, video.height = stream.height || self.height || 240, 
        video.play(), video;
    }
    function resetVideoStreams(streams) {
        videos = [], (streams = streams || arrayOfMediaStreams).forEach(function(stream) {
            if (stream.getTracks().filter(function(t) {
                return 'video' === t.kind;
            }).length) {
                var video = getVideo(stream);
                video.stream = stream, videos.push(video);
            }
        });
    }
    0;
    that = 'undefined' != typeof global ? global : null, void 0 === RecordRTC && that && 'undefined' == typeof window && 'undefined' != typeof global && (global.navigator = {
        'userAgent': 'Fake/5.0 (FakeOS) AppleWebKit/123 (KHTML, like Gecko) Fake/12.3.4567.89 Fake/123.45',
        'getUserMedia': function() {}
    }, global.console || (global.console = {}), void 0 !== global.console.log && void 0 !== global.console.error || (global.console.error = global.console.log = global.console.log || function() {}), 
    'undefined' == typeof document && (that.document = {
        'documentElement': {
            'appendChild': function() {
                return '';
            }
        }
    }, document.createElement = document.captureStream = document.mozCaptureStream = function() {
        var obj = {
            'getContext': function() {
                return obj;
            },
            'play': function() {},
            'pause': function() {},
            'drawImage': function() {},
            'toDataURL': function() {
                return '';
            },
            'style': {}
        };
        return obj;
    }, that.HTMLVideoElement = function() {}), 'undefined' == typeof location && (that.location = {
        'protocol': 'file:',
        'href': '',
        'hash': ''
    }), 'undefined' == typeof screen && (that.screen = {
        'width': 0,
        'height': 0
    }), void 0 === URL && (that.URL = {
        'createObjectURL': function() {
            return '';
        },
        'revokeObjectURL': function() {
            return '';
        }
    }), that.window = global), elementClass = elementClass || 'multi-streams-mixer';
    var that;
    isStopDrawingFrames = !(videos = []), canvas = document.createElement('canvas'), 
    context = canvas.getContext('2d');
    canvas.style.opacity = 0, canvas.style.position = 'absolute', canvas.style.zIndex = -1, 
    canvas.style.top = '-1000em', canvas.style.left = '-1000em', canvas.className = elementClass, 
    (document.body || document.documentElement).appendChild(canvas), this.disableLogs = !1, 
    this.frameInterval = 10, this.width = 360, this.height = 240, this.useGainNode = !0;
    self = this;
    void 0 === (that = window.AudioContext) && ('undefined' != typeof webkitAudioContext && (that = webkitAudioContext), 
    'undefined' != typeof mozAudioContext) && (that = mozAudioContext);
    void 0 === (URL = window.URL) && 'undefined' != typeof webkitURL && (URL = webkitURL), 
    'undefined' != typeof navigator && void 0 === navigator.getUserMedia && (void 0 !== navigator.webkitGetUserMedia && (navigator.getUserMedia = navigator.webkitGetUserMedia), 
    void 0 !== navigator.mozGetUserMedia) && (navigator.getUserMedia = navigator.mozGetUserMedia);
    void 0 !== (MediaStream = void 0 === (MediaStream = window.MediaStream) && 'undefined' != typeof webkitMediaStream ? webkitMediaStream : MediaStream) && void 0 === MediaStream.prototype.stop && (MediaStream.prototype.stop = function() {
        this.getTracks().forEach(function(track) {
            track.stop();
        });
    });
    Storage = {};
    void 0 !== that ? Storage.AudioContext = that : 'undefined' != typeof webkitAudioContext && (Storage.AudioContext = webkitAudioContext), 
    this.startDrawingFrames = function() {
        drawVideosToCanvas();
    }, this.appendStreams = function(streams) {
        if (!streams) throw 'First parameter is required.';
        (streams = streams instanceof Array ? streams : [ streams ]).forEach(function(stream) {
            var newStream, video;
            newStream = new MediaStream();
            stream.getTracks().filter(function(t) {
                return 'video' === t.kind;
            }).length && ((video = getVideo(stream)).stream = stream, videos.push(video), 
            newStream.addTrack(stream.getTracks().filter(function(t) {
                return 'video' === t.kind;
            })[0]));
            if (stream.getTracks().filter(function(t) {
                return 'audio' === t.kind;
            }).length) {
                video = self.audioContext.createMediaStreamSource(stream);
                self.audioDestination = self.audioContext.createMediaStreamDestination(), 
                video.connect(self.audioDestination), newStream.addTrack(self.audioDestination.stream.getTracks().filter(function(t) {
                    return 'audio' === t.kind;
                })[0]);
            }
            arrayOfMediaStreams.push(newStream);
        });
    }, this.releaseStreams = function() {
        videos = [], isStopDrawingFrames = !0, self.gainNode && (self.gainNode.disconnect(), 
        self.gainNode = null), self.audioSources.length && (self.audioSources.forEach(function(source) {
            source.disconnect();
        }), self.audioSources = []), self.audioDestination && (self.audioDestination.disconnect(), 
        self.audioDestination = null), self.audioContext && self.audioContext.close(), 
        self.audioContext = null, context.clearRect(0, 0, canvas.width, canvas.height), 
        canvas.stream && (canvas.stream.stop(), canvas.stream = null);
    }, this.resetVideoStreams = function(streams) {
        resetVideoStreams(streams = !streams || streams instanceof Array ? streams : [ streams ]);
    }, this.name = 'MultiStreamsMixer', this.toString = function() {
        return this.name;
    }, this.getMixedStream = function() {
        var mixedVideoStream, mixedAudioStream;
        isStopDrawingFrames = !1;
        mixedVideoStream = function() {
            var capturedStream, videoStream;
            resetVideoStreams();
            'captureStream' in canvas ? capturedStream = canvas.captureStream() : 'mozCaptureStream' in canvas ? capturedStream = canvas.mozCaptureStream() : self.disableLogs;
            videoStream = new MediaStream();
            return capturedStream.getTracks().filter(function(t) {
                return 'video' === t.kind;
            }).forEach(function(track) {
                videoStream.addTrack(track);
            }), canvas.stream = videoStream;
        }();
        (mixedAudioStream = function() {
            Storage.AudioContextConstructor || (Storage.AudioContextConstructor = new Storage.AudioContext()), 
            self.audioContext = Storage.AudioContextConstructor, self.audioSources = [], 
            !0 === self.useGainNode && (self.gainNode = self.audioContext.createGain(), 
            self.gainNode.connect(self.audioContext.destination), self.gainNode.gain.value = 0);
            var audioTracksLength = 0;
            if (arrayOfMediaStreams.forEach(function(stream) {
                if (stream.getTracks().filter(function(t) {
                    return 'audio' === t.kind;
                }).length) {
                    audioTracksLength++;
                    stream = self.audioContext.createMediaStreamSource(stream);
                    !0 === self.useGainNode && stream.connect(self.gainNode), self.audioSources.push(stream);
                }
            }), audioTracksLength) return self.audioDestination = self.audioContext.createMediaStreamDestination(), 
            self.audioSources.forEach(function(audioSource) {
                audioSource.connect(self.audioDestination);
            }), self.audioDestination.stream;
        }()) && mixedAudioStream.getTracks().filter(function(t) {
            return 'audio' === t.kind;
        }).forEach(function(track) {
            mixedVideoStream.addTrack(track);
        });
        return arrayOfMediaStreams.forEach(function(stream) {
            stream.fullcanvas;
        }), mixedVideoStream;
    };
}

function MultiStreamRecorder(arrayOfMediaStreams, options) {
    arrayOfMediaStreams = arrayOfMediaStreams || [];
    var mixer, mediaRecorder, self = this;
    (options = options || {
        'elementClass': 'multi-streams-mixer',
        'mimeType': 'video/webm',
        'video': {
            'width': 360,
            'height': 240
        }
    }).frameInterval || (options.frameInterval = 10), options.video || (options.video = {}), 
    options.video.width || (options.video.width = 360), options.video.height || (options.video.height = 240), 
    this.record = function() {
        mixer = new MultiStreamsMixer(arrayOfMediaStreams, options.elementClass || 'multi-streams-mixer'), 
        (tracks = [], arrayOfMediaStreams.forEach(function(stream) {
            getTracks(stream, 'video').forEach(function(track) {
                tracks.push(track);
            });
        }), tracks).length && (mixer.frameInterval = options.frameInterval || 10, 
        mixer.width = options.video.width || 360, mixer.height = options.video.height || 240, 
        mixer.startDrawingFrames()), options.previewStream && 'function' == typeof options.previewStream && options.previewStream(mixer.getMixedStream()), 
        (mediaRecorder = new MediaStreamRecorder(mixer.getMixedStream(), options)).record();
        var tracks;
    }, this.stop = function(callback) {
        mediaRecorder && mediaRecorder.stop(function(blob) {
            self.blob = blob, callback(blob), self.clearRecordedData();
        });
    }, this.pause = function() {
        mediaRecorder && mediaRecorder.pause();
    }, this.resume = function() {
        mediaRecorder && mediaRecorder.resume();
    }, this.clearRecordedData = function() {
        mediaRecorder && (mediaRecorder.clearRecordedData(), mediaRecorder = null), 
        mixer && (mixer.releaseStreams(), mixer = null);
    }, this.addStreams = function(streams) {
        if (!streams) throw 'First parameter is required.';
        streams instanceof Array || (streams = [ streams ]), arrayOfMediaStreams.concat(streams), 
        mediaRecorder && mixer && (mixer.appendStreams(streams), options.previewStream) && 'function' == typeof options.previewStream && options.previewStream(mixer.getMixedStream());
    }, this.resetVideoStreams = function(streams) {
        mixer && (!streams || streams instanceof Array || (streams = [ streams ]), 
        mixer.resetVideoStreams(streams));
    }, this.getMixer = function() {
        return mixer;
    }, this.name = 'MultiStreamRecorder', this.toString = function() {
        return this.name;
    };
}

function RecordRTCPromisesHandler(mediaStream, options) {
    if (!this) throw 'Use "new RecordRTCPromisesHandler()"';
    if (void 0 === mediaStream) throw 'First argument "MediaStream" is required.';
    var self = this;
    self.recordRTC = new RecordRTC(mediaStream, options), this.startRecording = function() {
        return new Promise(function(resolve, reject) {
            try {
                self.recordRTC.startRecording(), resolve();
            } catch (e) {
                reject(e);
            }
        });
    }, this.stopRecording = function() {
        return new Promise(function(resolve, reject) {
            try {
                self.recordRTC.stopRecording(function(url) {
                    return self.blob = self.recordRTC.getBlob(), self.blob && self.blob.size ? void resolve(url) : void reject('Empty blob.', self.blob);
                });
            } catch (e) {
                reject(e);
            }
        });
    }, this.pauseRecording = function() {
        return new Promise(function(resolve, reject) {
            try {
                self.recordRTC.pauseRecording(), resolve();
            } catch (e) {
                reject(e);
            }
        });
    }, this.resumeRecording = function() {
        return new Promise(function(resolve, reject) {
            try {
                self.recordRTC.resumeRecording(), resolve();
            } catch (e) {
                reject(e);
            }
        });
    }, this.getDataURL = function(callback) {
        return new Promise(function(resolve, reject) {
            try {
                self.recordRTC.getDataURL(function(dataURL) {
                    resolve(dataURL);
                });
            } catch (e) {
                reject(e);
            }
        });
    }, this.getBlob = function() {
        return new Promise(function(resolve, reject) {
            try {
                resolve(self.recordRTC.getBlob());
            } catch (e) {
                reject(e);
            }
        });
    }, this.getInternalRecorder = function() {
        return new Promise(function(resolve, reject) {
            try {
                resolve(self.recordRTC.getInternalRecorder());
            } catch (e) {
                reject(e);
            }
        });
    }, this.reset = function() {
        return new Promise(function(resolve, reject) {
            try {
                resolve(self.recordRTC.reset());
            } catch (e) {
                reject(e);
            }
        });
    }, this.destroy = function() {
        return new Promise(function(resolve, reject) {
            try {
                resolve(self.recordRTC.destroy());
            } catch (e) {
                reject(e);
            }
        });
    }, this.getState = function() {
        return new Promise(function(resolve, reject) {
            try {
                resolve(self.recordRTC.getState());
            } catch (e) {
                reject(e);
            }
        });
    }, this.blob = null, this.version = '5.5.9';
}

function WebAssemblyRecorder(stream, config) {
    var worker, isPaused, arrayOfBuffers;
    function cameraStream() {
        return new ReadableStream({
            'start': function(controller) {
                var cvs = document.createElement('canvas'), video = document.createElement('video');
                video.srcObject = stream, video.onplaying = function() {
                    cvs.width = config.width, cvs.height = config.height;
                    var ctx = cvs.getContext('2d'), frameTimeout = 1e3 / config.frameRate;
                    setTimeout(function f() {
                        ctx.drawImage(video, 0, 0), controller.enqueue(ctx.getImageData(0, 0, config.width, config.height)), 
                        setTimeout(f, frameTimeout);
                    }, frameTimeout);
                }, video.play();
            }
        });
    }
    (config = config || {}).width = config.width || 640, config.height = config.height || 480, 
    config.frameRate = config.frameRate || 30, config.bitrate = config.bitrate || 1200;
    this.record = function() {
        isPaused = !(arrayOfBuffers = []), this.blob = null, function startRecording(stream, buffer) {
            if (!config.workerPath && !buffer) return fetch('https://unpkg.com/webm-wasm@latest/dist/webm-worker.js').then(function(r) {
                r.arrayBuffer().then(function(buffer) {
                    startRecording(stream, buffer);
                });
            });
            if (!config.workerPath && buffer instanceof ArrayBuffer) {
                buffer = new Blob([ buffer ], {
                    'type': 'text/javascript'
                });
                config.workerPath = URL.createObjectURL(buffer);
            }
            config.workerPath, (worker = new Worker(config.workerPath)).postMessage(config.webAssemblyPath || 'https://unpkg.com/webm-wasm@latest/dist/webm-wasm.wasm'), 
            worker.addEventListener('message', function(event) {
                'READY' === event.data ? (worker.postMessage({
                    'width': config.width,
                    'height': config.height,
                    'bitrate': config.bitrate || 1200,
                    'timebaseDen': config.frameRate || 30,
                    'realtime': !0
                }), cameraStream().pipeTo(new WritableStream({
                    'write': function(image) {
                        worker && worker.postMessage(image.data.buffer, [ image.data.buffer ]);
                    }
                }))) : event.data && !isPaused && arrayOfBuffers.push(event.data);
            });
        }(stream), 'function' == typeof config.initCallback && config.initCallback();
    };
    this.pause = function() {
        isPaused = !0;
    }, this.resume = function() {
        isPaused = !1;
    };
    arrayOfBuffers = [];
    this.stop = function(callback) {
        worker && (worker.postMessage(null), worker.terminate(), worker = null), 
        this.blob = new Blob(arrayOfBuffers, {
            'type': 'video/webm'
        }), callback(this.blob);
    }, this.name = 'WebAssemblyRecorder', this.toString = function() {
        return this.name;
    }, this.clearRecordedData = function() {
        isPaused = !(arrayOfBuffers = []), this.blob = null;
    }, this.blob = null;
}

RecordRTC.version = '5.5.9', 'undefined' != typeof module && (module.exports = RecordRTC), 
'function' == typeof define && define.amd && define('RecordRTC', [], function() {
    return RecordRTC;
}), RecordRTC.getFromDisk = function(type, callback) {
    if (!callback) throw 'callback is mandatory.';
    DiskStorage.Fetch(function(dataURL, _type) {
        'all' !== type && _type === type + 'Blob' && callback && callback(dataURL), 
        'all' === type && callback && callback(dataURL, _type.replace('Blob', ''));
    });
}, RecordRTC.writeToDisk = function(options) {
    (options = options || {}).audio && options.video && options.gif ? options.audio.getDataURL(function(audioDataURL) {
        options.video.getDataURL(function(videoDataURL) {
            options.gif.getDataURL(function(gifDataURL) {
                DiskStorage.Store({
                    'audioBlob': audioDataURL,
                    'videoBlob': videoDataURL,
                    'gifBlob': gifDataURL
                });
            });
        });
    }) : options.audio && options.video ? options.audio.getDataURL(function(audioDataURL) {
        options.video.getDataURL(function(videoDataURL) {
            DiskStorage.Store({
                'audioBlob': audioDataURL,
                'videoBlob': videoDataURL
            });
        });
    }) : options.audio && options.gif ? options.audio.getDataURL(function(audioDataURL) {
        options.gif.getDataURL(function(gifDataURL) {
            DiskStorage.Store({
                'audioBlob': audioDataURL,
                'gifBlob': gifDataURL
            });
        });
    }) : options.video && options.gif ? options.video.getDataURL(function(videoDataURL) {
        options.gif.getDataURL(function(gifDataURL) {
            DiskStorage.Store({
                'videoBlob': videoDataURL,
                'gifBlob': gifDataURL
            });
        });
    }) : options.audio ? options.audio.getDataURL(function(audioDataURL) {
        DiskStorage.Store({
            'audioBlob': audioDataURL
        });
    }) : options.video ? options.video.getDataURL(function(videoDataURL) {
        DiskStorage.Store({
            'videoBlob': videoDataURL
        });
    }) : options.gif && options.gif.getDataURL(function(gifDataURL) {
        DiskStorage.Store({
            'gifBlob': gifDataURL
        });
    });
}, MRecordRTC.getFromDisk = RecordRTC.getFromDisk, MRecordRTC.writeToDisk = RecordRTC.writeToDisk, 
void 0 !== RecordRTC && (RecordRTC.MRecordRTC = MRecordRTC);

browserFakeUserAgent = 'Fake/5.0 (FakeOS) AppleWebKit/123 (KHTML, like Gecko) Fake/12.3.4567.89 Fake/123.45';

!function(that) {
    that && 'undefined' == typeof window && 'undefined' != typeof global && (global.navigator = {
        'userAgent': browserFakeUserAgent,
        'getUserMedia': function() {}
    }, global.console || (global.console = {}), void 0 !== global.console.log && void 0 !== global.console.error || (global.console.error = global.console.log = global.console.log || function() {}), 
    'undefined' == typeof document && (that.document = {
        'documentElement': {
            'appendChild': function() {
                return '';
            }
        }
    }, document.createElement = document.captureStream = document.mozCaptureStream = function() {
        var obj = {
            'getContext': function() {
                return obj;
            },
            'play': function() {},
            'pause': function() {},
            'drawImage': function() {},
            'toDataURL': function() {
                return '';
            },
            'style': {}
        };
        return obj;
    }, that.HTMLVideoElement = function() {}), 'undefined' == typeof location && (that.location = {
        'protocol': 'file:',
        'href': '',
        'hash': ''
    }), 'undefined' == typeof screen && (that.screen = {
        'width': 0,
        'height': 0
    }), void 0 === URL && (that.URL = {
        'createObjectURL': function() {
            return '';
        },
        'revokeObjectURL': function() {
            return '';
        }
    }), that.window = global);
}('undefined' != typeof global ? global : null);

if (void 0 === (requestAnimationFrame = window.requestAnimationFrame)) if ('undefined' != typeof webkitRequestAnimationFrame) requestAnimationFrame = webkitRequestAnimationFrame; else if ('undefined' != typeof mozRequestAnimationFrame) requestAnimationFrame = mozRequestAnimationFrame; else if ('undefined' != typeof msRequestAnimationFrame) requestAnimationFrame = msRequestAnimationFrame; else if (void 0 === requestAnimationFrame) {
    lastTime = 0;
    requestAnimationFrame = function(callback, element) {
        var currTime = new Date().getTime(), timeToCall = Math.max(0, 16 - (currTime - lastTime)), id = setTimeout(function() {
            callback(currTime + timeToCall);
        }, timeToCall);
        return lastTime = currTime + timeToCall, id;
    };
}

void 0 === (cancelAnimationFrame = window.cancelAnimationFrame) && ('undefined' != typeof webkitCancelAnimationFrame ? cancelAnimationFrame = webkitCancelAnimationFrame : 'undefined' != typeof mozCancelAnimationFrame ? cancelAnimationFrame = mozCancelAnimationFrame : 'undefined' != typeof msCancelAnimationFrame ? cancelAnimationFrame = msCancelAnimationFrame : void 0 === cancelAnimationFrame && (cancelAnimationFrame = function(id) {
    clearTimeout(id);
}));

void 0 === (AudioContext = window.AudioContext) && ('undefined' != typeof webkitAudioContext && (AudioContext = webkitAudioContext), 
'undefined' != typeof mozAudioContext) && (AudioContext = mozAudioContext);

void 0 === (URL = window.URL) && 'undefined' != typeof webkitURL && (URL = webkitURL), 
'undefined' != typeof navigator && void 0 === navigator.getUserMedia && (void 0 !== navigator.webkitGetUserMedia && (navigator.getUserMedia = navigator.webkitGetUserMedia), 
void 0 !== navigator.mozGetUserMedia) && (navigator.getUserMedia = navigator.mozGetUserMedia);

isEdge = !(-1 === navigator.userAgent.indexOf('Edge') || !navigator.msSaveBlob && !navigator.msSaveOrOpenBlob), 
isOpera = !!window.opera || -1 !== navigator.userAgent.indexOf('OPR/'), isFirefox = -1 < navigator.userAgent.toLowerCase().indexOf('firefox') && 'netscape' in window && / rv:/.test(navigator.userAgent), 
isChrome = !isOpera && !isEdge && !!navigator.webkitGetUserMedia || isElectron() || -1 !== navigator.userAgent.toLowerCase().indexOf('chrome/');

(isSafari = /^((?!chrome|android).)*safari/i.test(navigator.userAgent)) && !isChrome && -1 !== navigator.userAgent.indexOf('CriOS') && (isChrome = !(isSafari = !1));

void 0 !== (MediaStream = void 0 === (MediaStream = window.MediaStream) && 'undefined' != typeof webkitMediaStream ? webkitMediaStream : MediaStream) && void 0 === MediaStream.prototype.stop && (MediaStream.prototype.stop = function() {
    this.getTracks().forEach(function(track) {
        track.stop();
    });
}), void 0 !== RecordRTC && (RecordRTC.invokeSaveAsDialog = invokeSaveAsDialog, 
RecordRTC.getTracks = getTracks, RecordRTC.getSeekableBlob = getSeekableBlob, RecordRTC.bytesToSize = bytesToSize, 
RecordRTC.isElectron = isElectron);

Storage = {};

void 0 !== AudioContext ? Storage.AudioContext = AudioContext : 'undefined' != typeof webkitAudioContext && (Storage.AudioContext = webkitAudioContext), 
void 0 !== RecordRTC && (RecordRTC.Storage = Storage), void 0 !== RecordRTC && (RecordRTC.MediaStreamRecorder = MediaStreamRecorder), 
void 0 !== RecordRTC && (RecordRTC.StereoAudioRecorder = StereoAudioRecorder), void 0 !== RecordRTC && (RecordRTC.CanvasRecorder = CanvasRecorder), 
void 0 !== RecordRTC && (RecordRTC.WhammyRecorder = WhammyRecorder);

Whammy = function() {
    function WhammyVideo(duration) {
        this.frames = [], this.duration = duration || 1, this.quality = .8;
    }
    function whammyInWebWorker(frames) {
        function numToBuffer(num) {
            for (var parts = []; 0 < num; ) parts.push(255 & num), num >>= 8;
            return new Uint8Array(parts.reverse());
        }
        function strToBuffer(str) {
            return new Uint8Array(str.split('').map(function(e) {
                return e.charCodeAt(0);
            }));
        }
        function bitsToBuffer(bits) {
            var data, i;
            data = [];
            bits = (bits.length % 8 ? new Array(9 - bits.length % 8).join('0') : '') + bits;
            for (i = 0; i < bits.length; i += 8) data.push(parseInt(bits.substr(i, 8), 2));
            return new Uint8Array(data);
        }
        function parseRIFF(string) {
            var offset, chunks, id, len, data;
            for (offset = 0, chunks = {}; offset < string.length; ) {
                id = string.substr(offset, 4), len = function(string, offset) {
                    return parseInt(string.substr(offset + 4, 4).split('').map(function(i) {
                        i = i.charCodeAt(0).toString(2);
                        return new Array(8 - i.length + 1).join('0') + i;
                    }).join(''), 2);
                }(string, offset), data = string.substr(offset + 4 + 4, len);
                offset += 8 + len, chunks[id] = chunks[id] || [], 'RIFF' === id || 'LIST' === id ? chunks[id].push(parseRIFF(data)) : chunks[id].push(data);
            }
            return chunks;
        }
        frames = new function(frames) {
            var info, EBML, frameNumber, clusterTimecode, clusterFrames, clusterDuration, cluster, num;
            if (!(info = function(frames) {
                if (!frames[0]) return void postMessage({
                    'error': 'Something went wrong. Maybe WebP format is not supported in the current browser.'
                });
                for (var width = frames[0].width, height = frames[0].height, duration = frames[0].duration, i = 1; i < frames.length; i++) duration += frames[i].duration;
                return {
                    'duration': duration,
                    'width': width,
                    'height': height
                };
            }(frames))) return [];
            for (EBML = [ {
                'id': 440786851,
                'data': [ {
                    'data': 1,
                    'id': 17030
                }, {
                    'data': 1,
                    'id': 17143
                }, {
                    'data': 4,
                    'id': 17138
                }, {
                    'data': 8,
                    'id': 17139
                }, {
                    'data': 'webm',
                    'id': 17026
                }, {
                    'data': 2,
                    'id': 17031
                }, {
                    'data': 2,
                    'id': 17029
                } ]
            }, {
                'id': 408125543,
                'data': [ {
                    'id': 357149030,
                    'data': [ {
                        'data': 1e6,
                        'id': 2807729
                    }, {
                        'data': 'whammy',
                        'id': 19840
                    }, {
                        'data': 'whammy',
                        'id': 22337
                    }, {
                        'data': (num = info.duration, [].slice.call(new Uint8Array(new Float64Array([ num ]).buffer), 0).map(function(e) {
                            return String.fromCharCode(e);
                        }).reverse().join('')),
                        'id': 17545
                    } ]
                }, {
                    'id': 374648427,
                    'data': [ {
                        'id': 174,
                        'data': [ {
                            'data': 1,
                            'id': 215
                        }, {
                            'data': 1,
                            'id': 29637
                        }, {
                            'data': 0,
                            'id': 156
                        }, {
                            'data': 'und',
                            'id': 2274716
                        }, {
                            'data': 'V_VP8',
                            'id': 134
                        }, {
                            'data': 'VP8',
                            'id': 2459272
                        }, {
                            'data': 1,
                            'id': 131
                        }, {
                            'id': 224,
                            'data': [ {
                                'data': info.width,
                                'id': 176
                            }, {
                                'data': info.height,
                                'id': 186
                            } ]
                        } ]
                    } ]
                } ]
            } ], clusterTimecode = frameNumber = 0; frameNumber < frames.length; ) {
                clusterFrames = [], clusterDuration = 0;
                for (;clusterFrames.push(frames[frameNumber]), clusterDuration += frames[frameNumber].duration, 
                ++frameNumber < frames.length && clusterDuration < 3e4; );
                cluster = {
                    'id': 524531317,
                    'data': function(clusterTimecode, clusterCounter, clusterFrames) {
                        return [ {
                            'data': clusterTimecode,
                            'id': 231
                        } ].concat(clusterFrames.map(function(webp) {
                            var block = function(data) {
                                var flags;
                                flags = 0;
                                if (data.keyframe && (flags |= 128), data.invisible && (flags |= 8), 
                                data.lacing && (flags |= data.lacing << 1), data.discardable && (flags |= 1), 
                                127 < data.trackNum) throw 'TrackNumber > 127 not supported';
                                return [ 128 | data.trackNum, data.timecode >> 8, 255 & data.timecode, flags ].map(function(e) {
                                    return String.fromCharCode(e);
                                }).join('') + data.frame;
                            }({
                                'discardable': 0,
                                'frame': webp.data.slice(4),
                                'invisible': 0,
                                'keyframe': 1,
                                'lacing': 0,
                                'trackNum': 1,
                                'timecode': Math.round(clusterCounter)
                            });
                            return clusterCounter += webp.duration, {
                                'data': block,
                                'id': 163
                            };
                        }));
                    }(clusterTimecode, 0, clusterFrames)
                };
                EBML[1].data.push(cluster), clusterTimecode += clusterDuration;
            }
            return function generateEBML(json) {
                var ebml, i, data, len, zeroes;
                for (ebml = [], i = 0; i < json.length; i++) {
                    'string' == typeof (data = 'number' == typeof (data = 'object' == typeof (data = json[i].data) ? generateEBML(data) : data) ? bitsToBuffer(data.toString(2)) : data) && (data = strToBuffer(data));
                    len = data.size || data.byteLength || data.length, zeroes = Math.ceil(Math.ceil(Math.log(len) / Math.log(2)) / 8), 
                    len = len.toString(2), len = new Array(7 * zeroes + 7 + 1 - len.length).join('0') + len, 
                    zeroes = new Array(zeroes).join('0') + '1' + len;
                    ebml.push(numToBuffer(json[i].id)), ebml.push(bitsToBuffer(zeroes)), 
                    ebml.push(data);
                }
                return new Blob(ebml, {
                    'type': 'video/webm'
                });
            }(EBML);
        }(frames.map(function(frame) {
            var webp = function(riff) {
                var VP8, frameStart, i, c;
                for (frameStart = (VP8 = riff.RIFF[0].WEBP[0]).indexOf('*'), i = 0, 
                c = []; i < 4; i++) c[i] = VP8.charCodeAt(frameStart + 3 + i);
                return {
                    'width': 16383 & (c[1] << 8 | c[0]),
                    'height': 16383 & (c[3] << 8 | c[2]),
                    'data': VP8,
                    'riff': riff
                };
            }(parseRIFF(atob(frame.image.slice(23))));
            return webp.duration = frame.duration, webp;
        }));
        postMessage(frames);
    }
    return WhammyVideo.prototype.add = function(frame, duration) {
        if ('toDataURL' in (frame = 'canvas' in frame ? frame.canvas : frame) && (frame = frame.toDataURL('image/webp', this.quality)), 
        !/^data:image\/webp;base64,/gi.test(frame)) throw 'Input must be formatted properly as a base64 encoded DataURI of type image/webp';
        this.frames.push({
            'image': frame,
            'duration': duration || this.duration
        });
    }, WhammyVideo.prototype.compile = function(callback) {
        _function = whammyInWebWorker, _function = URL.createObjectURL(new Blob([ _function.toString(), 'this.onmessage =  function (eee) {' + _function.name + '(eee.data);}' ], {
            'type': 'application/javascript'
        })), worker = new Worker(_function), URL.revokeObjectURL(_function);
        _function = worker;
        var _function, worker;
        _function.onmessage = function(event) {
            return event.data.error ? void 0 : void callback(event.data);
        }, _function.postMessage(this.frames);
    }, {
        'Video': WhammyVideo
    };
}();

void 0 !== RecordRTC && (RecordRTC.Whammy = Whammy);

DiskStorage = {
    'init': function() {
        var self, db, dbName, request;
        function createObjectStore(dataBase) {
            dataBase.createObjectStore(self.dataStoreName);
        }
        function putInDB() {
            function getFromStore(portionName) {
                transaction.objectStore(self.dataStoreName).get(portionName).onsuccess = function(event) {
                    self.callback && self.callback(event.target.result, portionName);
                };
            }
            var transaction = db.transaction([ self.dataStoreName ], 'readwrite');
            self.videoBlob && transaction.objectStore(self.dataStoreName).put(self.videoBlob, 'videoBlob'), 
            self.gifBlob && transaction.objectStore(self.dataStoreName).put(self.gifBlob, 'gifBlob'), 
            self.audioBlob && transaction.objectStore(self.dataStoreName).put(self.audioBlob, 'audioBlob'), 
            getFromStore('audioBlob'), getFromStore('videoBlob'), getFromStore('gifBlob');
        }
        self = this;
        if ('undefined' == typeof indexedDB || void 0 === indexedDB.open) return;
        dbName = this.dbName || location.href.replace(/\/|:|#|%|\.|\[|\]/g, '');
        (request = indexedDB.open(dbName, 1)).onerror = self.onError, request.onsuccess = function() {
            ((db = request.result).onerror = self.onError, db.setVersion) && 1 !== db.version ? db.setVersion(1).onsuccess = function() {
                createObjectStore(db), putInDB();
            } : putInDB();
        }, request.onupgradeneeded = function(event) {
            createObjectStore(event.target.result);
        };
    },
    'Fetch': function(callback) {
        return this.callback = callback, this.init(), this;
    },
    'Store': function(config) {
        return this.audioBlob = config.audioBlob, this.videoBlob = config.videoBlob, 
        this.gifBlob = config.gifBlob, this.init(), this;
    },
    'onError': function(error) {},
    'dataStoreName': 'recordRTC',
    'dbName': null
};

void 0 !== RecordRTC && (RecordRTC.DiskStorage = DiskStorage), void 0 !== RecordRTC && (RecordRTC.GifRecorder = GifRecorder), 
void 0 === RecordRTC && ('undefined' != typeof module && (module.exports = MultiStreamsMixer), 
'function' == typeof define) && define.amd && define('MultiStreamsMixer', [], function() {
    return MultiStreamsMixer;
}), void 0 !== RecordRTC && (RecordRTC.MultiStreamRecorder = MultiStreamRecorder), 
void 0 !== RecordRTC && (RecordRTC.RecordRTCPromisesHandler = RecordRTCPromisesHandler), 
void 0 !== RecordRTC && (RecordRTC.WebAssemblyRecorder = WebAssemblyRecorder);